{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pdefind import *\n",
    "from PDE_Equation import pde_matrix_mul, sparse_coeff, normalized_xi_threshold, pde_Recover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158661, 3) (158661, 1)\n",
      "X: [[ 3.  -5.  -5. ]\n",
      " [ 3.1 -5.  -5. ]\n",
      " [ 3.2 -5.  -5. ]\n",
      " ...\n",
      " [ 8.8  5.   5. ]\n",
      " [ 8.9  5.   5. ]\n",
      " [ 9.   5.   5. ]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "data = sio.loadmat(os.path.join(os.getcwd(), \"data\", \"Advection_diffusion.mat\"))\n",
    "usol = np.real(data['Expression1'])\n",
    "usol= usol.reshape((51,51,61,4))\n",
    "\n",
    "x = usol[:,:,:,0]\n",
    "y = usol[:,:,:,1]\n",
    "t = usol[:,:,:,2]\n",
    "u = usol[:,:,:,3]\n",
    "\n",
    "X = np.transpose((t.flatten(),x.flatten(), y.flatten()))\n",
    "y = u.reshape((u.size, 1))\n",
    "print(X.shape, y.shape)\n",
    "print('X:', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Add noise\n",
    "noise_level = 0.1\n",
    "y_noisy = y + noise_level * np.std(y) * np.random.randn(y.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape torch.Size([2000, 3])\n",
      "y_train shape torch.Size([2000, 1])\n"
     ]
    }
   ],
   "source": [
    "#number_of_samples = 2000\n",
    "#idx = np.random.permutation(y.size)\n",
    "#X_train = X[idx, :][:number_of_samples]\n",
    "#y_train = y_noisy[idx, :][:number_of_samples]\n",
    "#print('X_train', X_train.shape)\n",
    "#print('y_train', y_train.shape)\n",
    "\n",
    "idxs = np.random.choice(y.size, 2000, replace=False)\n",
    "\n",
    "X_train = torch.tensor(X[idxs], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y_noisy[idxs], dtype=torch.float32)\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "#print(\"X shape\", X.shape)\n",
    "#print(\"y shape\", y.shape)\n",
    "#print('X_train', X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library_coeffs: ['1', 'u_{x}', 'u_{y}', 'u_{xx}', 'u_{yy}', 'u_{xy}', 'u', 'uu_{x}', 'uu_{y}', 'uu_{xx}', 'uu_{yy}', 'uu_{xy}']\n",
      "tot_items: 12\n"
     ]
    }
   ],
   "source": [
    "polynm = ['1', 'u']\n",
    "spa_der = ['1', 'u_{x}', 'u_{y}','u_{xx}', 'u_{yy}','u_{xy}']\n",
    "library_coeffs = pde_matrix_mul(polynm, spa_der)\n",
    "print('library_coeffs:', library_coeffs)\n",
    "\n",
    "tot_items = len(library_coeffs)\n",
    "print('tot_items:', tot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=20, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=20, out_features=15, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=15, out_features=10, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=5, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup Network\n",
    "net = PINN(sizes=[3,20,15,10,5,1], activation=torch.nn.Tanh())\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 7.1000,  4.2000, -1.2000],\n",
      "        [ 5.5000,  4.0000, -4.6000],\n",
      "        [ 6.2000,  2.0000, -4.6000],\n",
      "        ...,\n",
      "        [ 8.0000, -2.6000, -3.6000],\n",
      "        [ 8.7000,  2.6000,  3.6000],\n",
      "        [ 3.3000,  1.6000, -1.8000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#X_train = torch.from_numpy(X_train)\n",
    "print(type(X_train))\n",
    "uhat = net(X_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Construct Library\n",
    "def build_library_2D(data, uhat, poly_order, deriv_order):\n",
    "    # build polynomials\n",
    "    poly = torch.ones_like(uhat)\n",
    "    \n",
    "    # concatinate different orders\n",
    "    for o in np.arange(1, poly_order+1):\n",
    "        poly_o = poly[:,o-1:o]*uhat\n",
    "        poly = torch.cat((poly, poly_o), dim=1)\n",
    "        print('poly.shape', poly.shape)\n",
    "        \n",
    "    # build derivatives\n",
    "    # returns gradient of uhat w.r.t. data (id0=spatial, id1=temporal)\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    dudt = du[:, 0:1]\n",
    "    dudx = du[:, 1:2]\n",
    "    dudy = du[:, 2:3]\n",
    "    dudu = grad(outputs=dudx, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    dudxx = dudu[:, 1:2]\n",
    "    dudxy = dudu[:, 2:3]\n",
    "    dudyy = grad(outputs=dudy, inputs=data, \n",
    "              grad_outputs=torch.ones_like(dudxx), create_graph=True)[0]\n",
    "   \n",
    "    #dudu = torch.cat((torch.ones_like(dudt), du[:,0:1]), dim=1)\n",
    "    dudu = torch.cat((torch.ones_like(dudx), dudx, dudy, dudxx, dudyy[:, 2:3], dudxy), dim=1)\n",
    "    #for order in np.arange(2, library_config['deriv_order']+1):\n",
    "    #    du = tf.concat((du, tf.gradients(du[:, order-1], data)[0][:, 0:1]), axis=1)\n",
    "    \n",
    "    #for o in np.arange(1, deriv_order):\n",
    "        #du2 = grad(outputs=dudu[:,o:o+1], inputs=data, \n",
    "                  #grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "       # dudx = torch.cat((dudx, du2[:,0:1]), dim=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # build all possible combinations of poly and dudx vectors\n",
    "    theta = None\n",
    "    for i in range(poly_order+1):\n",
    "        #print('i:', i)\n",
    "        for j in range(5+1):\n",
    "            #print('j:', j)\n",
    "            comb = poly[:,i:i+1] * dudu[:,j:j+1]\n",
    "            \n",
    "            if theta is None:\n",
    "                theta = comb\n",
    "            else:\n",
    "                theta = torch.cat((theta, comb), dim=1)\n",
    "                \n",
    "    return dudu, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly.shape torch.Size([2000, 2])\n",
      "theta: torch.Size([2000, 12])\n",
      "dudu.shape: torch.Size([2000, 6])\n"
     ]
    }
   ],
   "source": [
    "uhat = net(X_train)\n",
    "dudu, theta = build_library_2D(X_train, uhat, poly_order=1, deriv_order=2)\n",
    "#print(dudu.shape)\n",
    "print('theta:', theta.shape)\n",
    "print('dudu.shape:', dudu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Construct Library\n",
    "def build_library_2D(data, uhat, poly_order, deriv_order):\n",
    "    # build polynomials\n",
    "    poly = torch.ones_like(uhat)\n",
    "    \n",
    "    # concatinate different orders\n",
    "    for o in np.arange(1, poly_order+1):\n",
    "        poly_o = poly[:,o-1:o]*uhat\n",
    "        poly = torch.cat((poly, poly_o), dim=1)\n",
    "        print('poly.shape:', poly.shape)\n",
    "        \n",
    "    # build derivatives\n",
    "    # returns gradient of uhat w.r.t. data (id0=spatial, id1=temporal)\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    return du\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly.shape: torch.Size([2000, 2])\n",
      "tensor([[-0.0177,  0.0255, -0.0112],\n",
      "        [-0.0169,  0.0155, -0.0049],\n",
      "        [-0.0133,  0.0201, -0.0073],\n",
      "        ...,\n",
      "        [-0.0025,  0.0029,  0.0014],\n",
      "        [-0.0008,  0.0097, -0.0053],\n",
      "        [-0.0281,  0.0375, -0.0153]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "uhat = net(X_train)\n",
    "du = build_library_2D(X_train, uhat, poly_order=1, deriv_order=2)\n",
    "print(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Construct Library\n",
    "def build_library_2D(data, uhat, poly_order, deriv_order):\n",
    "    # build polynomials\n",
    "    poly = torch.ones_like(uhat)\n",
    "    \n",
    "    # concatinate different orders\n",
    "    for o in np.arange(1, poly_order+1):\n",
    "        poly_o = poly[:,o-1:o]*uhat\n",
    "        poly = torch.cat((poly, poly_o), dim=1)\n",
    "        \n",
    "    # build derivatives\n",
    "    # returns gradient of uhat w.r.t. data (id0=spatial, id1=temporal)\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    u_t = du[:, 0:1]\n",
    "    u_x = du[:, 1:2]\n",
    "    u_y = du[:, 2:3]\n",
    "    du2 = tf.gradients(u_x,data)[0]\n",
    "    u_xx = du2[:, 1:2]\n",
    "    u_xy = du2[:, 2:3]\n",
    "    u_yy = grad(outputs=u_y[:, 2:3], inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    #tf.gradients(u_y,data)[0][:, 2:3]\n",
    "    du = torch.cat((torch.ones_like(u_x), u_x, u_y , u_xx, u_yy, u_xy), dim=1)\n",
    "    \n",
    "    return du\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-204be9efd3ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0muhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_library_2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderiv_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-8ddfc0e63068>\u001b[0m in \u001b[0;36mbuild_library_2D\u001b[1;34m(data, uhat, poly_order, deriv_order)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mu_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mu_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdu2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mu_xx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mu_xy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    159\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;31m# cluster ops for compilation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[0mgradient_uid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"uid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_n_to_tensor_or_indexed_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m     xs = [\n\u001b[0;32m    596\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_resource_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_n_to_tensor_or_indexed_slices\u001b[1;34m(values, dtype, name)\u001b[0m\n\u001b[0;32m   1454\u001b[0m   \"\"\"\n\u001b[0;32m   1455\u001b[0m   return internal_convert_n_to_tensor_or_indexed_slices(\n\u001b[1;32m-> 1456\u001b[1;33m       values=values, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor_or_indexed_slices\u001b[1;34m(values, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1426\u001b[0m       ret.append(\n\u001b[0;32m   1427\u001b[0m           internal_convert_to_tensor_or_indexed_slices(\n\u001b[1;32m-> 1428\u001b[1;33m               value, dtype=dtype, name=n, as_ref=as_ref))\n\u001b[0m\u001b[0;32m   1429\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     return internal_convert_to_tensor(\n\u001b[1;32m-> 1388\u001b[1;33m         value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    303\u001b[0m                                          as_ref=False):\n\u001b[0;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    244\u001b[0m   \"\"\"\n\u001b[0;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 246\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[0;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;31m# If a class has the __array__ method, or __array_interface__ dict, then it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;31m# is possible to convert to numpy array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m     \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# This is the preferred way to create an array from the object, so replace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "uhat = net(X_train)\n",
    "du = build_library_2D(X_train, uhat, poly_order=2, deriv_order=2)\n",
    "print(du)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Construct Library\n",
    "def build_library_2D(data, uhat, poly_order, deriv_order):\n",
    "    # build polynomials\n",
    "    poly = torch.ones_like(uhat)\n",
    "    \n",
    "    # concatinate different orders\n",
    "    for o in np.arange(1, poly_order+1):\n",
    "        poly_o = poly[:,o-1:o]*uhat\n",
    "        poly = torch.cat((poly, poly_o), dim=1)\n",
    "        \n",
    "    # build derivatives\n",
    "    # returns gradient of uhat w.r.t. data (id0=spatial, id1=temporal)\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    dudt = du[:, 0:1]\n",
    "    dudx = du[:, 1:2]\n",
    "    dudy = du[:, 2:3]\n",
    "    dudu = grad(outputs=dudx, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    dudxx = dudu[:, 1:2]\n",
    "    dudxy = dudu[:, 2:3]\n",
    "    dudyy = grad(outputs=dudy[:, 2:3], inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "   \n",
    "    dudu = torch.cat((torch.ones_like(dudt), du[:,0:1]), dim=1)\n",
    "   # torch.cat((torch.ones_like(dudx), dudx, dudy, dudxx, dudyy, dudxy), dim=1)\n",
    "    #for order in np.arange(2, library_config['deriv_order']+1):\n",
    "    #    du = tf.concat((du, tf.gradients(du[:, order-1], data)[0][:, 0:1]), axis=1)\n",
    "    \n",
    "    for o in np.arange(1, deriv_order):\n",
    "        du2 = grad(outputs=dudu[:,o:o+1], inputs=data, \n",
    "                  grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "        dudx = torch.cat((dudx, du2[:,0:1]), dim=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # build all possible combinations of poly and dudx vectors\n",
    "    theta = None\n",
    "    for i in range(poly_order+1):\n",
    "        for j in range(deriv_order+1):\n",
    "            comb = poly[:,i:i+1] * dudu[:,j:j+1]\n",
    "            \n",
    "            if theta is None:\n",
    "                theta = comb\n",
    "            else:\n",
    "                theta = torch.cat((theta, comb), dim=1)\n",
    "                \n",
    "    return dudt, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Library\n",
    "def build_library_2D(data, uhat, poly_order, deriv_order):\n",
    "    # build polynomials\n",
    "    poly = torch.ones_like(uhat)\n",
    "    \n",
    "    # concatinate different orders\n",
    "    for o in np.arange(1, poly_order+1):\n",
    "        poly_o = poly[:,o-1:o]*uhat\n",
    "        poly = torch.cat((poly, poly_o), dim=1)\n",
    "        \n",
    "    # build derivatives\n",
    "    # returns gradient of uhat w.r.t. data (id0=spatial, id1=temporal)\n",
    "    du = grad(outputs=uhat, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    \n",
    "    dudt = du[:, 0:1]\n",
    "    dudx = du[:, 1:2]\n",
    "    dudy = du[:, 2:3]\n",
    "    dudu = grad(outputs=dudx, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    dudxx = dudu[:, 1:2]\n",
    "    dudxy = dudu[:, 2:3]\n",
    "    dudyy = grad(outputs=dudy, inputs=data, \n",
    "              grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "   \n",
    "    #dudu = torch.cat((torch.ones_like(dudt), du[:,0:1]), dim=1)\n",
    "    dudu = torch.cat((torch.ones_like(dudx), dudx, dudy, dudxx, dudyy, dudxy), dim=1)\n",
    "    #for order in np.arange(2, library_config['deriv_order']+1):\n",
    "    #    du = tf.concat((du, tf.gradients(du[:, order-1], data)[0][:, 0:1]), axis=1)\n",
    "    \n",
    "    for o in np.arange(1, deriv_order):\n",
    "        du2 = grad(outputs=dudu[:,o:o+1], inputs=data, \n",
    "                  grad_outputs=torch.ones_like(uhat), create_graph=True)[0]\n",
    "    dudu = torch.cat((dudu, du2[:,0:1]), dim=1)\n",
    "\n",
    "\n",
    "    \n",
    "    # build all possible combinations of poly and dudx vectors\n",
    "    theta = None\n",
    "    for i in range(poly_order+1):\n",
    "        for j in range(deriv_order+1):\n",
    "            comb = poly[:,i:i+1] * dudu[:,j:j+1]\n",
    "            \n",
    "            if theta is None:\n",
    "                theta = comb\n",
    "            else:\n",
    "                theta = torch.cat((theta, comb), dim=1)\n",
    "                \n",
    "    return dudt, theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
