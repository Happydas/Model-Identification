{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Advection-Diffusion Equation\n",
    "\n",
    "$$u_t = 0.25u_{x} + 0.5 u_{y} + 0.5u_{xx} + 0.5 u_{yy}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pdefind import *\n",
    "from Model_Identification.PDE_Equation import pde_matrix_mul, sparse_coeff, normalized_xi_threshold, pde_Recover\n",
    "from Model_Identification.build_Library import construct_Dictonary_2D\n",
    "from datetime import datetime\n",
    "import numba.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.shape (634644, 1)\n",
      "u.shape (51, 51, 61)\n",
      "x.shape (51, 51, 61)\n",
      "t.shape (51, 51, 61)\n",
      "y.shape (51, 51, 61)\n",
      "(51, 51)\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Prepare dataset\n",
    "data = sio.loadmat(os.path.join(os.getcwd(), \"../data\", \"Advection_diffusion.mat\"))\n",
    "usol = np.real(data['Expression1'])\n",
    "print('u.shape', usol.shape)\n",
    "usol= usol.reshape((51,51,61,4))\n",
    "#u = data[\"usol\"]\n",
    "x = usol[:,:,:,0]\n",
    "y = usol[:,:,:,1]\n",
    "t = usol[:,:,:,2]\n",
    "u = usol[:,:,:,3]\n",
    "print('u.shape', u.shape)\n",
    "print('x.shape', x.shape)\n",
    "print('t.shape', t.shape)\n",
    "print('y.shape', y.shape)\n",
    "print(x[:,:,10].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.contourf(x[:,:,10], y[:,:,10], u[:,:,10], cmap='seismic')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "fig.colorbar(mappable=im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158661, 3) (158661, 1)\n",
      "X: [[ 3.  -5.  -5. ]\n",
      " [ 3.1 -5.  -5. ]\n",
      " [ 3.2 -5.  -5. ]\n",
      " ...\n",
      " [ 8.8  5.   5. ]\n",
      " [ 8.9  5.   5. ]\n",
      " [ 9.   5.   5. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.transpose((t.flatten(),x.flatten(), y.flatten()))\n",
    "Y = u.reshape((u.size, 1))\n",
    "print(X.shape, Y.shape)\n",
    "print('X:', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add noise\n",
    "np.random.seed(0)\n",
    "noise_level = 0.01\n",
    "y = Y + noise_level * np.std(Y) * np.random.randn(Y.size, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=30, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=30, out_features=30, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=30, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup Network\n",
    "net = PINN(sizes=[3,30,30,30,30,30,1], activation=torch.nn.Tanh())\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library_coeffs: ['1', 'u_{x}', 'u_{y}', 'u_{xx}', 'u_{yy}', 'u_{xy}', 'u', 'uu_{x}', 'uu_{y}', 'uu_{xx}', 'uu_{yy}', 'uu_{xy}']\n",
      "tot_items: 12\n"
     ]
    }
   ],
   "source": [
    "polynm = ['1', 'u']\n",
    "spa_der = ['1', 'u_{x}', 'u_{y}','u_{xx}', 'u_{yy}','u_{xy}']\n",
    "library_coeffs = pde_matrix_mul(polynm, spa_der)\n",
    "print('library_coeffs:', library_coeffs)\n",
    "\n",
    "tot_items = len(library_coeffs)\n",
    "print('tot_items:', tot_items)\n",
    "\n",
    "mask = torch.ones(tot_items, 1)\n",
    "epochs = 10000\n",
    "xi = nn.Parameter(torch.randn((tot_items, 1), requires_grad=True, device=\"cpu\", dtype=torch.float32))\n",
    "#params = [{'params': net.parameters(), 'lr': 3e-3}, {'params': xi, 'lr': 3e-2}]\n",
    "params = [{'params': net.parameters(), 'lr': 1e-3}, {'params': xi, 'lr': 1e-2}]\n",
    "\n",
    "optimizer = Adam(params)\n",
    "scheduler = ExponentialLR(optimizer, .9998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_identification(features, label, mask, poly_order, deriv_order):\n",
    "    \n",
    "    xi1 = []\n",
    "    xi2 = []\n",
    "    xi3 = []\n",
    "    xi4 = []\n",
    "    xi1_error_app = []\n",
    "    xi2_error_app = []\n",
    "    xi3_error_app = []\n",
    "    xi4_error_app = []\n",
    "    xi_update_app = []\n",
    "    \n",
    "    numbers = [0, 5, 26, 57, 73, 80, 95, 104, 129, 151]\n",
    "    \n",
    "    #f1 = open(\"Results/Average_errors.txt\", \"a+\", encoding=\"utf-8\")\n",
    "    #f2 = open(\"Results/Average_xi.txt\", \"a+\", encoding=\"utf-8\")\n",
    "\n",
    "    correct_prediction = 0\n",
    "    # Using for loop\n",
    "    for i in numbers:\n",
    "        np.random.seed(i)\n",
    "        print('seed:', i)\n",
    "        idxs = np.random.choice(y.size, 2000, replace=False)\n",
    "        X_train = torch.tensor(features[idxs], dtype=torch.float32, requires_grad=True)\n",
    "        y_train = torch.tensor(label[idxs], dtype=torch.float32)\n",
    "    \n",
    "        lamb   = 0\n",
    "        tolerance = 1e-6\n",
    "        mask = torch.ones(tot_items, 1)\n",
    "        #print('xi', xi)\n",
    "        print('mask:', mask.shape)\n",
    "        lambd  = 1e-6\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            uhat = net(X_train)\n",
    "    \n",
    "            if epoch == 1000:\n",
    "                lamb = 1\n",
    "               \n",
    "            dudt, theta = construct_Dictonary_2D(X_train, uhat, poly_order=1, deriv_order=2)\n",
    "            #print('dudt:', dudt.shape)\n",
    "            dudt_norm = torch.norm(dudt, dim=0)\n",
    "    \n",
    "            theta_scaling = (torch.norm(theta, dim=0))\n",
    "            #Returns a new tensor with a dimension of size one inserted at the specified position. from 9 it will be 9,1\n",
    "            theta_norm = torch.unsqueeze(theta_scaling, dim = 1) \n",
    "            xi_normalized = xi * (theta_norm / dudt_norm) \n",
    "            L1 = lambd * torch.sum(torch.abs(xi_normalized[1:, :]))\n",
    "        \n",
    "            l_u   = nn.MSELoss()(uhat, y_train)\n",
    "            l_reg = lamb * torch.mean((dudt - theta @ xi)**2)\n",
    "            #l_reg = torch.mean((dudt - theta @ xi)**2)\n",
    "\n",
    "            loss = l_u + l_reg + L1\n",
    "\n",
    "            gradient_loss = torch.max(torch.abs(grad(outputs=loss, inputs=xi, \n",
    "                  grad_outputs=torch.ones_like(loss), create_graph=True)[0]) / (theta_norm / dudt_norm))\n",
    "\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        \n",
    "            if epoch % 1000 == 0:\n",
    "                print('loss:', epoch, loss)\n",
    "                if gradient_loss < tolerance:\n",
    "                    print('Optimizer converged.')\n",
    "                    break\n",
    " \n",
    "        xi_list = sparse_coeff(mask, xi.detach().numpy())\n",
    "        xi_normalized = sparse_coeff(mask, xi_normalized.detach().numpy())\n",
    "        print('xi_normalized:', xi_normalized)\n",
    "    \n",
    "\n",
    "        sparsity = normalized_xi_threshold( xi_normalized, mode='auto')\n",
    "        print('sparsity:', sparsity)\n",
    "    \n",
    "        xi_thresholded = np.expand_dims(xi_list[sparsity], axis=1) \n",
    "        print('xi_thresholded:', xi_thresholded)\n",
    "        \n",
    "        print('Coefficient xi:')\n",
    "        xi_update = sparse_coeff(sparsity, xi_thresholded)\n",
    "        print('xi_update:', xi_update)\n",
    "        \n",
    "    \n",
    "        # Calculate Error in xi    \n",
    "        if xi_update[1] != 0 and xi_update[2] != 0 and xi_update[3] != 0 and xi_update[4] != 0 and len(xi_thresholded) < 5:\n",
    "            xi_update_app.append(xi_update)\n",
    "            #print('xi_update_app:', xi_update_app)\n",
    "            print('xi_update:', xi_update[1], xi_update[2], xi_update[3], xi_update[4])\n",
    "            error_1 = np.subtract(np.array([0.25000]),xi_update[1])\n",
    "            xi1_error = np.append(xi1, error_1)\n",
    "            print('xi1_error', xi1_error)\n",
    "            error_2 = np.subtract(np.array([0.50000]),xi_update[2])\n",
    "            xi2_error = np.append(xi2, error_2)\n",
    "            print('xi2_error', xi2_error)\n",
    "            error_3 = np.subtract(np.array([0.50000]),xi_update[3])\n",
    "            xi3_error = np.append(xi3, error_3)\n",
    "            print('xi3_error', xi3_error)\n",
    "            error_4 = np.subtract(np.array([0.50000]),xi_update[4])\n",
    "            xi4_error = np.append(xi4, error_4)\n",
    "            print('xi4_error', xi4_error)\n",
    "            xi1_error_app.append(xi1_error)\n",
    "            print('xi1_error_app:', xi1_error_app)\n",
    "            xi2_error_app.append(xi2_error)\n",
    "            print('xi2_error_app:', xi2_error_app)\n",
    "            xi3_error_app.append(xi3_error)\n",
    "            print('xi3_error_app:', xi3_error_app)\n",
    "            xi4_error_app.append(xi4_error)\n",
    "            print('xi4_error_app:', xi4_error_app)\n",
    "            correct_prediction += 1\n",
    "            \n",
    "        else:\n",
    "            print('PDE prediction not correct')\n",
    "            \n",
    "            \n",
    "    print('correct_prediction:', correct_prediction)\n",
    "    Accuracy = correct_prediction / len(numbers) * 100\n",
    "    print('Accuracy:', Accuracy)\n",
    "    xi1_error_avg = np.sum(xi1_error_app, axis = 0) / correct_prediction  \n",
    "    print('xi1_error_avg:', xi1_error_avg)\n",
    "    xi2_error_avg = np.sum(xi2_error_app, axis = 0) / correct_prediction \n",
    "    print('xi2_error_avg:', xi2_error_avg)\n",
    "    xi3_error_avg = np.sum(xi3_error_app, axis = 0) / correct_prediction  \n",
    "    print('xi3_error_avg:', xi3_error_avg)\n",
    "    xi4_error_avg = np.sum(xi4_error_app, axis = 0) / correct_prediction \n",
    "    print('xi4_error_avg:', xi4_error_avg)\n",
    "    #f1.write(str(xi1_error_avg) + \" \" + str(xi2_error_avg) + \" \" + str(xi3_error_avg) + \" \" + str(xi4_error_avg) +  \"\\n\")\n",
    "    xi_updated = np.sum(xi_update_app, axis = 0) / correct_prediction  \n",
    "    print('xi_updated:', xi_updated)\n",
    "    #f2.write(str(xi_updated[1]) + \" \" + str(xi_updated[2]) + \" \" + str(xi_updated[3]) + \" \" + str(xi_updated[4]) +  \"\\n\")\n",
    "    print('Finished')\n",
    "    return xi_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.4324, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0392, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 0.04491149]\n",
      " [ 0.36170197]\n",
      " [ 0.69431549]\n",
      " [ 0.39797962]\n",
      " [ 0.332993  ]\n",
      " [-0.02445797]\n",
      " [-0.09652743]\n",
      " [ 0.00843447]\n",
      " [-0.00355259]\n",
      " [-0.04292577]\n",
      " [ 0.01389514]\n",
      " [ 0.01842812]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.24496725]\n",
      " [0.48943162]\n",
      " [0.48736596]\n",
      " [0.41669714]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.24496725]\n",
      " [0.48943162]\n",
      " [0.48736596]\n",
      " [0.41669714]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.24496725] [0.48943162] [0.48736596] [0.41669714]\n",
      "xi1_error [0.00503275]\n",
      "xi2_error [0.01056838]\n",
      "xi3_error [0.01263404]\n",
      "xi4_error [0.08330286]\n",
      "xi1_error_app: [array([0.00503275])]\n",
      "xi2_error_app: [array([0.01056838])]\n",
      "xi3_error_app: [array([0.01263404])]\n",
      "xi4_error_app: [array([0.08330286])]\n",
      "seed: 5\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(7.5431e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(9.0921e-05, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 0.03326847]\n",
      " [ 0.36783728]\n",
      " [ 0.70694375]\n",
      " [ 0.37609428]\n",
      " [ 0.34072596]\n",
      " [-0.01402184]\n",
      " [-0.06328656]\n",
      " [-0.00437913]\n",
      " [ 0.00157754]\n",
      " [-0.01469364]\n",
      " [ 0.00104242]\n",
      " [ 0.01234825]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25372851]\n",
      " [0.4900915 ]\n",
      " [0.4846468 ]\n",
      " [0.44132262]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25372851]\n",
      " [0.4900915 ]\n",
      " [0.4846468 ]\n",
      " [0.44132262]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25372851] [0.4900915] [0.4846468] [0.44132262]\n",
      "xi1_error [-0.00372851]\n",
      "xi2_error [0.0099085]\n",
      "xi3_error [0.0153532]\n",
      "xi4_error [0.05867738]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738])]\n",
      "seed: 26\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(5.5336e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(6.2701e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(9.5541e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(4.7993e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(4.6787e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(4.0129e-05, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 3.28341662e-03]\n",
      " [ 3.40459824e-01]\n",
      " [ 6.44857168e-01]\n",
      " [ 3.90107512e-01]\n",
      " [ 3.84542286e-01]\n",
      " [-2.31625536e-03]\n",
      " [-1.02441460e-02]\n",
      " [-7.05059720e-05]\n",
      " [ 2.52622133e-03]\n",
      " [ 3.79317370e-03]\n",
      " [-1.43684773e-02]\n",
      " [ 4.20831097e-03]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25134465]\n",
      " [0.49564257]\n",
      " [0.49818262]\n",
      " [0.50110281]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25134465]\n",
      " [0.49564257]\n",
      " [0.49818262]\n",
      " [0.50110281]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25134465] [0.49564257] [0.49818262] [0.50110281]\n",
      "xi1_error [-0.00134465]\n",
      "xi2_error [0.00435743]\n",
      "xi3_error [0.00181738]\n",
      "xi4_error [-0.00110281]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281])]\n",
      "seed: 57\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(3.1753e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(7.3223e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(3.4959e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(3.3746e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(3.3369e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(3.2146e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(3.1078e-05, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(3.0750e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[ 1.27861416e-03]\n",
      " [ 3.38820308e-01]\n",
      " [ 6.55911505e-01]\n",
      " [ 3.97807032e-01]\n",
      " [ 3.82189572e-01]\n",
      " [ 1.32232974e-03]\n",
      " [-7.66166719e-03]\n",
      " [-1.79658504e-03]\n",
      " [ 6.42120559e-03]\n",
      " [-1.07038133e-02]\n",
      " [-8.97163339e-03]\n",
      " [-4.74679382e-06]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25197804]\n",
      " [0.49445805]\n",
      " [0.50880337]\n",
      " [0.50129277]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25197804]\n",
      " [0.49445805]\n",
      " [0.50880337]\n",
      " [0.50129277]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25197804] [0.49445805] [0.50880337] [0.50129277]\n",
      "xi1_error [-0.00197804]\n",
      "xi2_error [0.00554195]\n",
      "xi3_error [-0.00880337]\n",
      "xi4_error [-0.00129277]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277])]\n",
      "seed: 73\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(3.0618e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(3.1940e-05, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(3.0901e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(5.6508e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(3.0195e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(3.0015e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(3.3358e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(8.0904e-05, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(4.7743e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-6.00218482e-04]\n",
      " [ 3.56589526e-01]\n",
      " [ 6.59871578e-01]\n",
      " [ 4.22387362e-01]\n",
      " [ 4.04743463e-01]\n",
      " [ 5.58658467e-05]\n",
      " [-1.73818914e-03]\n",
      " [-4.20985714e-04]\n",
      " [ 7.86875375e-03]\n",
      " [-1.20341284e-02]\n",
      " [-3.65730841e-04]\n",
      " [ 1.19937409e-03]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25201547]\n",
      " [0.49473578]\n",
      " [0.51115698]\n",
      " [0.49845544]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25201547]\n",
      " [0.49473578]\n",
      " [0.51115698]\n",
      " [0.49845544]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25201547] [0.49473578] [0.51115698] [0.49845544]\n",
      "xi1_error [-0.00201547]\n",
      "xi2_error [0.00526422]\n",
      "xi3_error [-0.01115698]\n",
      "xi4_error [0.00154456]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456])]\n",
      "seed: 80\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(2.8976e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(2.9990e-05, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 4.68356448e-04]\n",
      " [ 3.51030231e-01]\n",
      " [ 6.80756271e-01]\n",
      " [ 4.05285865e-01]\n",
      " [ 4.03558910e-01]\n",
      " [-3.41487321e-04]\n",
      " [-4.26973775e-03]\n",
      " [ 1.64513709e-03]\n",
      " [ 7.15552014e-05]\n",
      " [-5.88330813e-03]\n",
      " [-6.81800628e-03]\n",
      " [ 9.63724684e-04]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.24931398]\n",
      " [0.4994927 ]\n",
      " [0.50751078]\n",
      " [0.50062108]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.24931398]\n",
      " [0.4994927 ]\n",
      " [0.50751078]\n",
      " [0.50062108]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.24931398] [0.4994927] [0.50751078] [0.50062108]\n",
      "xi1_error [0.00068602]\n",
      "xi2_error [0.0005073]\n",
      "xi3_error [-0.00751078]\n",
      "xi4_error [-0.00062108]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547]), array([0.00068602])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422]), array([0.0005073])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698]), array([-0.00751078])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456]), array([-0.00062108])]\n",
      "seed: 95\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(2.9809e-05, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(3.0466e-05, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(2.9824e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(2.8700e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(3.2697e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(3.9559e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(2.9473e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(2.7921e-05, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(3.0151e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-3.28881503e-03]\n",
      " [ 3.34347904e-01]\n",
      " [ 6.90343499e-01]\n",
      " [ 3.86114568e-01]\n",
      " [ 3.83774042e-01]\n",
      " [-4.29028121e-04]\n",
      " [-2.60160188e-04]\n",
      " [ 4.86850506e-03]\n",
      " [-1.23645389e-03]\n",
      " [ 1.03484578e-02]\n",
      " [ 2.48838915e-04]\n",
      " [ 1.55577785e-04]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.24585423]\n",
      " [0.50076306]\n",
      " [0.48957014]\n",
      " [0.50046897]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.24585423]\n",
      " [0.50076306]\n",
      " [0.48957014]\n",
      " [0.50046897]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.24585423] [0.50076306] [0.48957014] [0.50046897]\n",
      "xi1_error [0.00414577]\n",
      "xi2_error [-0.00076306]\n",
      "xi3_error [0.01042986]\n",
      "xi4_error [-0.00046897]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547]), array([0.00068602]), array([0.00414577])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422]), array([0.0005073]), array([-0.00076306])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698]), array([-0.00751078]), array([0.01042986])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456]), array([-0.00062108]), array([-0.00046897])]\n",
      "seed: 104\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(3.4458e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(4.7234e-05, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(2.8074e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(3.4875e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(2.7612e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(3.4972e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(2.8465e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(2.7161e-05, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(6.1436e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-7.43983896e-04]\n",
      " [ 3.58212560e-01]\n",
      " [ 6.48241460e-01]\n",
      " [ 3.93068343e-01]\n",
      " [ 3.97426486e-01]\n",
      " [ 3.44748702e-03]\n",
      " [-1.52376975e-04]\n",
      " [-7.63851102e-04]\n",
      " [ 4.52723587e-03]\n",
      " [-3.68003710e-03]\n",
      " [ 5.05195279e-03]\n",
      " [-2.84792343e-03]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25121093]\n",
      " [0.49702096]\n",
      " [0.50408041]\n",
      " [0.4936083 ]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25121093]\n",
      " [0.49702096]\n",
      " [0.50408041]\n",
      " [0.4936083 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25121093] [0.49702096] [0.50408041] [0.4936083]\n",
      "xi1_error [-0.00121093]\n",
      "xi2_error [0.00297904]\n",
      "xi3_error [-0.00408041]\n",
      "xi4_error [0.0063917]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547]), array([0.00068602]), array([0.00414577]), array([-0.00121093])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422]), array([0.0005073]), array([-0.00076306]), array([0.00297904])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698]), array([-0.00751078]), array([0.01042986]), array([-0.00408041])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456]), array([-0.00062108]), array([-0.00046897]), array([0.0063917])]\n",
      "seed: 129\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(2.8405e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(2.8019e-05, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(2.8478e-05, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(2.7784e-05, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(2.7406e-05, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(2.7375e-05, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(2.7334e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(3.9021e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[ 2.90446123e-03]\n",
      " [ 3.46580118e-01]\n",
      " [ 7.10833728e-01]\n",
      " [ 4.06319350e-01]\n",
      " [ 3.97020131e-01]\n",
      " [ 7.92996958e-04]\n",
      " [-1.71927933e-03]\n",
      " [ 4.31839935e-03]\n",
      " [-1.02463912e-03]\n",
      " [ 6.77572738e-04]\n",
      " [ 1.88038612e-04]\n",
      " [-2.24513840e-03]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.2465    ]\n",
      " [0.50146466]\n",
      " [0.4991248 ]\n",
      " [0.49797869]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.2465    ]\n",
      " [0.50146466]\n",
      " [0.4991248 ]\n",
      " [0.49797869]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.2465] [0.50146466] [0.4991248] [0.49797869]\n",
      "xi1_error [0.0035]\n",
      "xi2_error [-0.00146466]\n",
      "xi3_error [0.0008752]\n",
      "xi4_error [0.00202131]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547]), array([0.00068602]), array([0.00414577]), array([-0.00121093]), array([0.0035])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422]), array([0.0005073]), array([-0.00076306]), array([0.00297904]), array([-0.00146466])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698]), array([-0.00751078]), array([0.01042986]), array([-0.00408041]), array([0.0008752])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456]), array([-0.00062108]), array([-0.00046897]), array([0.0063917]), array([0.00202131])]\n",
      "seed: 151\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(3.3301e-05, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(2.8938e-05, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 1.97296985e-03]\n",
      " [ 3.55637759e-01]\n",
      " [ 6.88123465e-01]\n",
      " [ 4.02094901e-01]\n",
      " [ 3.93338859e-01]\n",
      " [-2.81263003e-03]\n",
      " [-6.87322870e-04]\n",
      " [-1.54528447e-04]\n",
      " [-8.94986806e-06]\n",
      " [ 5.28250122e-03]\n",
      " [-2.41830992e-03]\n",
      " [ 1.94921670e-03]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.25036588]\n",
      " [0.49969333]\n",
      " [0.4984023 ]\n",
      " [0.4990938 ]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.25036588]\n",
      " [0.49969333]\n",
      " [0.4984023 ]\n",
      " [0.4990938 ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "xi_update: [0.25036588] [0.49969333] [0.4984023] [0.4990938]\n",
      "xi1_error [-0.00036588]\n",
      "xi2_error [0.00030667]\n",
      "xi3_error [0.0015977]\n",
      "xi4_error [0.0009062]\n",
      "xi1_error_app: [array([0.00503275]), array([-0.00372851]), array([-0.00134465]), array([-0.00197804]), array([-0.00201547]), array([0.00068602]), array([0.00414577]), array([-0.00121093]), array([0.0035]), array([-0.00036588])]\n",
      "xi2_error_app: [array([0.01056838]), array([0.0099085]), array([0.00435743]), array([0.00554195]), array([0.00526422]), array([0.0005073]), array([-0.00076306]), array([0.00297904]), array([-0.00146466]), array([0.00030667])]\n",
      "xi3_error_app: [array([0.01263404]), array([0.0153532]), array([0.00181738]), array([-0.00880337]), array([-0.01115698]), array([-0.00751078]), array([0.01042986]), array([-0.00408041]), array([0.0008752]), array([0.0015977])]\n",
      "xi4_error_app: [array([0.08330286]), array([0.05867738]), array([-0.00110281]), array([-0.00129277]), array([0.00154456]), array([-0.00062108]), array([-0.00046897]), array([0.0063917]), array([0.00202131]), array([0.0009062])]\n",
      "correct_prediction: 10\n",
      "Accuracy: 100.0\n",
      "xi1_error_avg: [0.00027211]\n",
      "xi2_error_avg: [0.00372058]\n",
      "xi3_error_avg: [0.00111558]\n",
      "xi4_error_avg: [0.01493584]\n",
      "xi_updated: [[0.        ]\n",
      " [0.24972789]\n",
      " [0.49627942]\n",
      " [0.49888442]\n",
      " [0.48506416]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "xi_updated = model_identification(X, y, mask, poly_order=1, deriv_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burger equation:\n",
      "u_t = 0.250u_{x} + 0.496u_{y} + 0.499u_{xx} + 0.485u_{yy}\n",
      "Duration: 1:08:03.904378\n"
     ]
    }
   ],
   "source": [
    "pde_Recover(xi_updated, library_coeffs, equation_form='u_t')\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
