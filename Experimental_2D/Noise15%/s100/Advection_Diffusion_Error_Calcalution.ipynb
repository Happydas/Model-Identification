{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Advection-Diffusion Equation\n",
    "\n",
    "$$u_t = 0.25u_{x} + 0.5 u_{y} + 0.5u_{xx} + 0.5 u_{yy}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from pdefind import *\n",
    "from Model_Identification.PDE_Equation import pde_matrix_mul, sparse_coeff, normalized_xi_threshold, pde_Recover\n",
    "from Model_Identification.build_Library import construct_Dictonary_2D\n",
    "from datetime import datetime\n",
    "import numba.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u.shape (634644, 1)\n",
      "u.shape (51, 51, 61)\n",
      "x.shape (51, 51, 61)\n",
      "t.shape (51, 51, 61)\n",
      "y.shape (51, 51, 61)\n",
      "(51, 51)\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Prepare dataset\n",
    "data = sio.loadmat(os.path.join(os.getcwd(), \"../data\", \"Advection_diffusion.mat\"))\n",
    "usol = np.real(data['Expression1'])\n",
    "print('u.shape', usol.shape)\n",
    "usol= usol.reshape((51,51,61,4))\n",
    "#u = data[\"usol\"]\n",
    "x = usol[:,:,:,0]\n",
    "y = usol[:,:,:,1]\n",
    "t = usol[:,:,:,2]\n",
    "u = usol[:,:,:,3]\n",
    "print('u.shape', u.shape)\n",
    "print('x.shape', x.shape)\n",
    "print('t.shape', t.shape)\n",
    "print('y.shape', y.shape)\n",
    "print(x[:,:,10].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "im = ax.contourf(x[:,:,10], y[:,:,10], u[:,:,10], cmap='seismic')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "fig.colorbar(mappable=im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158661, 3) (158661, 1)\n",
      "X: [[ 3.  -5.  -5. ]\n",
      " [ 3.1 -5.  -5. ]\n",
      " [ 3.2 -5.  -5. ]\n",
      " ...\n",
      " [ 8.8  5.   5. ]\n",
      " [ 8.9  5.   5. ]\n",
      " [ 9.   5.   5. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.transpose((t.flatten(),x.flatten(), y.flatten()))\n",
    "Y = u.reshape((u.size, 1))\n",
    "print(X.shape, Y.shape)\n",
    "print('X:', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add noise\n",
    "np.random.seed(0)\n",
    "noise_level = 0.15\n",
    "y = Y + noise_level * np.std(Y) * np.random.randn(Y.size, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=20, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setup Network\n",
    "net = PINN(sizes=[3,20,20,20,20,20,1], activation=torch.nn.Tanh())\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library_coeffs: ['1', 'u_{x}', 'u_{y}', 'u_{xx}', 'u_{yy}', 'u_{xy}', 'u', 'uu_{x}', 'uu_{y}', 'uu_{xx}', 'uu_{yy}', 'uu_{xy}']\n",
      "tot_items: 12\n"
     ]
    }
   ],
   "source": [
    "polynm = ['1', 'u']\n",
    "spa_der = ['1', 'u_{x}', 'u_{y}','u_{xx}', 'u_{yy}','u_{xy}']\n",
    "library_coeffs = pde_matrix_mul(polynm, spa_der)\n",
    "print('library_coeffs:', library_coeffs)\n",
    "\n",
    "tot_items = len(library_coeffs)\n",
    "print('tot_items:', tot_items)\n",
    "\n",
    "mask = torch.ones(tot_items, 1)\n",
    "epochs = 10000\n",
    "xi = nn.Parameter(torch.randn((tot_items, 1), requires_grad=True, device=\"cpu\", dtype=torch.float32))\n",
    "#params = [{'params': net.parameters(), 'lr': 3e-3}, {'params': xi, 'lr': 3e-2}]\n",
    "params = [{'params': net.parameters(), 'lr': 1e-3}, {'params': xi, 'lr': 1e-2}]\n",
    "\n",
    "optimizer = Adam(params)\n",
    "scheduler = ExponentialLR(optimizer, .9998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_identification(features, label, mask, poly_order, deriv_order):\n",
    "    \n",
    "    xi1 = []\n",
    "    xi2 = []\n",
    "    xi3 = []\n",
    "    xi4 = []\n",
    "    xi1_error_app = []\n",
    "    xi2_error_app = []\n",
    "    xi3_error_app = []\n",
    "    xi4_error_app = []\n",
    "    xi_update_app = []\n",
    "    \n",
    "    numbers = [0, 5, 26, 57, 73, 80, 95, 104, 129, 151]\n",
    "    \n",
    "    f1 = open(\"Results/Average_errors.txt\", \"w+\", encoding=\"utf-8\")\n",
    "    f2 = open(\"Results/Average_xi.txt\", \"w+\", encoding=\"utf-8\")\n",
    "\n",
    "    correct_prediction = 0\n",
    "    # Using for loop\n",
    "    for i in numbers:\n",
    "        np.random.seed(i)\n",
    "        print('seed:', i)\n",
    "        idxs = np.random.choice(y.size, 100, replace=False)\n",
    "        X_train = torch.tensor(features[idxs], dtype=torch.float32, requires_grad=True)\n",
    "        y_train = torch.tensor(label[idxs], dtype=torch.float32)\n",
    "    \n",
    "        lamb   = 0\n",
    "        tolerance = 1e-6\n",
    "        mask = torch.ones(tot_items, 1)\n",
    "        #print('xi', xi)\n",
    "        print('mask:', mask.shape)\n",
    "        lambd  = 1e-6\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            uhat = net(X_train)\n",
    "    \n",
    "            if epoch == 1000:\n",
    "                lamb = 1\n",
    "               \n",
    "            dudt, theta = construct_Dictonary_2D(X_train, uhat, poly_order=1, deriv_order=2)\n",
    "            #print('dudt:', dudt.shape)\n",
    "            dudt_norm = torch.norm(dudt, dim=0)\n",
    "    \n",
    "            theta_scaling = (torch.norm(theta, dim=0))\n",
    "            #Returns a new tensor with a dimension of size one inserted at the specified position. from 9 it will be 9,1\n",
    "            theta_norm = torch.unsqueeze(theta_scaling, dim = 1) \n",
    "            xi_normalized = xi * (theta_norm / dudt_norm) \n",
    "            L1 = lambd * torch.sum(torch.abs(xi_normalized[1:, :]))\n",
    "        \n",
    "            l_u   = nn.MSELoss()(uhat, y_train)\n",
    "            l_reg = lamb * torch.mean((dudt - theta @ xi)**2)\n",
    "            #l_reg = torch.mean((dudt - theta @ xi)**2)\n",
    "\n",
    "            loss = l_u + l_reg + L1\n",
    "\n",
    "            gradient_loss = torch.max(torch.abs(grad(outputs=loss, inputs=xi, \n",
    "                  grad_outputs=torch.ones_like(loss), create_graph=True)[0]) / (theta_norm / dudt_norm))\n",
    "\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        \n",
    "            if epoch % 1000 == 0:\n",
    "                print('loss:', epoch, loss)\n",
    "                if gradient_loss < tolerance:\n",
    "                    print('Optimizer converged.')\n",
    "                    break\n",
    " \n",
    "        xi_list = sparse_coeff(mask, xi.detach().numpy())\n",
    "        xi_normalized = sparse_coeff(mask, xi_normalized.detach().numpy())\n",
    "        print('xi_normalized:', xi_normalized)\n",
    "    \n",
    "\n",
    "        sparsity = normalized_xi_threshold( xi_normalized, mode='auto')\n",
    "        print('sparsity:', sparsity)\n",
    "    \n",
    "        xi_thresholded = np.expand_dims(xi_list[sparsity], axis=1) \n",
    "        print('xi_thresholded:', xi_thresholded)\n",
    "        \n",
    "        print('Coefficient xi:')\n",
    "        xi_update = sparse_coeff(sparsity, xi_thresholded)\n",
    "        print('xi_update:', xi_update)\n",
    "        \n",
    "    \n",
    "        # Calculate Error in xi    \n",
    "        if xi_update[1] != 0 and xi_update[2] != 0 and xi_update[3] != 0 and xi_update[4] != 0 and len(xi_thresholded) < 5:\n",
    "            xi_update_app.append(xi_update)\n",
    "            #print('xi_update_app:', xi_update_app)\n",
    "            print('xi_update:', xi_update[1], xi_update[2], xi_update[3], xi_update[4])\n",
    "            error_1 = np.subtract(np.array([0.25000]),xi_update[1])\n",
    "            xi1_error = np.append(xi1, error_1)\n",
    "            print('xi1_error', xi1_error)\n",
    "            error_2 = np.subtract(np.array([0.50000]),xi_update[2])\n",
    "            xi2_error = np.append(xi2, error_2)\n",
    "            print('xi2_error', xi2_error)\n",
    "            error_3 = np.subtract(np.array([0.50000]),xi_update[3])\n",
    "            xi3_error = np.append(xi3, error_3)\n",
    "            print('xi3_error', xi3_error)\n",
    "            error_4 = np.subtract(np.array([0.50000]),xi_update[4])\n",
    "            xi4_error = np.append(xi4, error_4)\n",
    "            print('xi4_error', xi4_error)\n",
    "            xi1_error_app.append(xi1_error)\n",
    "            print('xi1_error_app:', xi1_error_app)\n",
    "            xi2_error_app.append(xi2_error)\n",
    "            print('xi2_error_app:', xi2_error_app)\n",
    "            xi3_error_app.append(xi3_error)\n",
    "            print('xi3_error_app:', xi3_error_app)\n",
    "            xi4_error_app.append(xi4_error)\n",
    "            print('xi4_error_app:', xi4_error_app)\n",
    "            correct_prediction += 1\n",
    "            \n",
    "        else:\n",
    "            print('PDE prediction not correct')\n",
    "            \n",
    "            \n",
    "    print('correct_prediction:', correct_prediction)\n",
    "    Accuracy = correct_prediction / len(numbers) * 100\n",
    "    print('Accuracy:', Accuracy)\n",
    "    xi1_error_avg = np.sum(xi1_error_app, axis = 0) / correct_prediction  \n",
    "    print('xi1_error_avg:', xi1_error_avg)\n",
    "    xi2_error_avg = np.sum(xi2_error_app, axis = 0) / correct_prediction \n",
    "    print('xi2_error_avg:', xi2_error_avg)\n",
    "    xi3_error_avg = np.sum(xi3_error_app, axis = 0) / correct_prediction  \n",
    "    print('xi3_error_avg:', xi3_error_avg)\n",
    "    xi4_error_avg = np.sum(xi4_error_app, axis = 0) / correct_prediction \n",
    "    print('xi4_error_avg:', xi4_error_avg)\n",
    "    f1.write(str(xi1_error_avg) + \" \" + str(xi2_error_avg) + \" \" + str(xi3_error_avg) + \" \" + str(xi4_error_avg) +  \"\\n\")\n",
    "    xi_updated = np.sum(xi_update_app, axis = 0) / correct_prediction  \n",
    "    print('xi_updated:', xi_updated)\n",
    "    f2.write(str(xi_updated[1]) + \" \" + str(xi_updated[2]) + \" \" + str(xi_updated[3]) + \" \" + str(xi_updated[4]) +  \"\\n\")\n",
    "    print('Finished')\n",
    "    return xi_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 0\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.3581, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(1.9285, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 0.15301821]\n",
      " [ 0.27312243]\n",
      " [ 0.59949696]\n",
      " [ 0.30787641]\n",
      " [-0.2614097 ]\n",
      " [-0.20179158]\n",
      " [-0.34846929]\n",
      " [ 0.41235143]\n",
      " [ 0.27899495]\n",
      " [ 0.04127488]\n",
      " [ 0.46598184]\n",
      " [ 0.28756109]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[ 0.41550493]\n",
      " [-0.13606498]\n",
      " [-0.25512767]\n",
      " [-0.06891394]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.41550493]\n",
      " [ 0.        ]\n",
      " [-0.13606498]\n",
      " [-0.25512767]\n",
      " [-0.06891394]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 5\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0175, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0113, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[ 0.0363446 ]\n",
      " [ 0.1201184 ]\n",
      " [ 0.09076527]\n",
      " [-0.24192159]\n",
      " [ 0.05368082]\n",
      " [-0.37780181]\n",
      " [-0.39227301]\n",
      " [ 0.54193765]\n",
      " [ 0.42410737]\n",
      " [ 0.54286063]\n",
      " [ 0.19385123]\n",
      " [ 0.08863559]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[-0.1635884 ]\n",
      " [-0.31339508]\n",
      " [-0.08908591]\n",
      " [ 0.41285887]\n",
      " [ 0.25910738]\n",
      " [ 0.2787945 ]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.1635884 ]\n",
      " [ 0.        ]\n",
      " [-0.31339508]\n",
      " [-0.08908591]\n",
      " [ 0.41285887]\n",
      " [ 0.25910738]\n",
      " [ 0.2787945 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 26\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0293, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0141, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 0.02200166]\n",
      " [-0.13102569]\n",
      " [ 0.11978024]\n",
      " [-0.25415519]\n",
      " [-0.7334857 ]\n",
      " [-0.36097714]\n",
      " [-0.41231143]\n",
      " [ 0.54945779]\n",
      " [ 0.59678441]\n",
      " [ 0.45373288]\n",
      " [ 0.55537403]\n",
      " [ 0.21764879]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]]\n",
      "xi_thresholded: [[-0.16242699]\n",
      " [-0.35037091]\n",
      " [-0.08926507]\n",
      " [ 0.32711652]\n",
      " [ 0.27266416]\n",
      " [ 0.14765789]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.16242699]\n",
      " [-0.35037091]\n",
      " [-0.08926507]\n",
      " [ 0.32711652]\n",
      " [ 0.27266416]\n",
      " [ 0.        ]\n",
      " [ 0.14765789]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 57\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0227, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-0.05641934]\n",
      " [ 0.14827307]\n",
      " [-0.10765895]\n",
      " [ 0.1914542 ]\n",
      " [-0.17003836]\n",
      " [ 0.15652266]\n",
      " [-0.20339583]\n",
      " [ 0.23302726]\n",
      " [ 0.91540128]\n",
      " [-0.22885579]\n",
      " [ 0.05039046]\n",
      " [-0.19100659]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.60002238]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.60002238]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 73\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0352, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0369, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[ 0.08899079]\n",
      " [ 0.08837932]\n",
      " [ 0.45593375]\n",
      " [ 0.0170915 ]\n",
      " [-0.59221947]\n",
      " [ 0.12510827]\n",
      " [-0.40422517]\n",
      " [ 0.31503442]\n",
      " [ 0.19256718]\n",
      " [-0.1162288 ]\n",
      " [ 0.27351299]\n",
      " [ 0.28226745]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[ 0.2946054 ]\n",
      " [-0.14895734]\n",
      " [-0.12509392]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.2946054 ]\n",
      " [ 0.        ]\n",
      " [-0.14895734]\n",
      " [ 0.        ]\n",
      " [-0.12509392]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 80\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0518, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0651, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "Optimizer converged.\n",
      "xi_normalized: [[-0.08347551]\n",
      " [-0.14633951]\n",
      " [-0.08032952]\n",
      " [-0.15004925]\n",
      " [ 0.31305581]\n",
      " [-0.02206283]\n",
      " [-0.42776316]\n",
      " [ 0.42181364]\n",
      " [ 0.96350825]\n",
      " [ 0.00792773]\n",
      " [-0.57632607]\n",
      " [-0.30713323]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]]\n",
      "xi_thresholded: [[ 0.04861902]\n",
      " [ 0.33277005]\n",
      " [ 0.45053303]\n",
      " [-0.08408239]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.04861902]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.33277005]\n",
      " [ 0.45053303]\n",
      " [ 0.        ]\n",
      " [-0.08408239]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 95\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0266, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0161, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-0.02594678]\n",
      " [-0.22111817]\n",
      " [-0.6097405 ]\n",
      " [-0.42624736]\n",
      " [-0.13597253]\n",
      " [-0.40747121]\n",
      " [-0.49845749]\n",
      " [ 0.62579936]\n",
      " [ 1.03859651]\n",
      " [ 0.05454112]\n",
      " [-0.16713515]\n",
      " [ 0.03865804]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[-0.42483145]\n",
      " [ 0.34864086]\n",
      " [ 0.9361077 ]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.42483145]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.34864086]\n",
      " [ 0.9361077 ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 104\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0568, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(7.1774e-05, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 7000 tensor(5.7687e-05, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(4.2079e-05, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(4.4929e-05, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-0.02788684]\n",
      " [-0.22898857]\n",
      " [-0.49877015]\n",
      " [-0.46607986]\n",
      " [-0.01435489]\n",
      " [-0.48969981]\n",
      " [-0.32542926]\n",
      " [ 0.68029225]\n",
      " [ 1.17082548]\n",
      " [-0.184094  ]\n",
      " [ 0.40746436]\n",
      " [ 0.02319739]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]]\n",
      "xi_thresholded: [[0.29447258]\n",
      " [0.70473093]\n",
      " [0.09796333]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.29447258]\n",
      " [0.70473093]\n",
      " [0.        ]\n",
      " [0.09796333]\n",
      " [0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 129\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0501, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-0.03539959]\n",
      " [-0.51897025]\n",
      " [-0.36315942]\n",
      " [ 0.20208718]\n",
      " [-0.29207593]\n",
      " [-0.25690049]\n",
      " [-0.57147259]\n",
      " [ 0.98038059]\n",
      " [ 1.27625942]\n",
      " [-0.3530533 ]\n",
      " [-0.26871869]\n",
      " [ 0.1062345 ]]\n",
      "sparsity: [[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n",
      "xi_thresholded: [[0.58068013]\n",
      " [0.85484207]]\n",
      "Coefficient xi:\n",
      "xi_update: [[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.58068013]\n",
      " [0.85484207]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "PDE prediction not correct\n",
      "seed: 151\n",
      "mask: torch.Size([12, 1])\n",
      "loss: 0 tensor(0.0311, grad_fn=<AddBackward0>)\n",
      "loss: 1000 tensor(0.0273, grad_fn=<AddBackward0>)\n",
      "loss: 2000 tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "loss: 3000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 4000 tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "loss: 5000 tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "loss: 6000 tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "loss: 7000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 8000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "loss: 9000 tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "xi_normalized: [[-0.05830147]\n",
      " [ 0.53934598]\n",
      " [ 0.46620217]\n",
      " [ 0.24825008]\n",
      " [-0.6663214 ]\n",
      " [-0.00096959]\n",
      " [ 0.02732339]\n",
      " [ 0.09305689]\n",
      " [ 0.18945904]\n",
      " [-0.06818639]\n",
      " [ 0.48151433]\n",
      " [-0.08114556]]\n",
      "sparsity: [[False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]]\n",
      "xi_thresholded: [[ 0.39728773]\n",
      " [ 0.32968727]\n",
      " [-0.21044494]\n",
      " [ 0.14820124]]\n",
      "Coefficient xi:\n",
      "xi_update: [[ 0.        ]\n",
      " [ 0.39728773]\n",
      " [ 0.32968727]\n",
      " [ 0.        ]\n",
      " [-0.21044494]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.14820124]\n",
      " [ 0.        ]]\n",
      "PDE prediction not correct\n",
      "correct_prediction: 0\n",
      "Accuracy: 0.0\n",
      "xi1_error_avg: nan\n",
      "xi2_error_avg: nan\n",
      "xi3_error_avg: nan\n",
      "xi4_error_avg: nan\n",
      "xi_updated: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:120: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:122: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:124: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:126: RuntimeWarning: invalid value encountered in double_scalars\n",
      "c:\\users\\happy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:129: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e101381e9bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxi_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_identification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderiv_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-432b1d6396c4>\u001b[0m in \u001b[0;36mmodel_identification\u001b[1;34m(features, label, mask, poly_order, deriv_order)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mxi_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_update_app\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xi_updated:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi_updated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_updated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_updated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_updated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi_updated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mxi_updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "xi_updated = model_identification(X, y, mask, poly_order=1, deriv_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pde_Recover(xi_updated, library_coeffs, equation_form='u_t')\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
